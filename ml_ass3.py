# -*- coding: utf-8 -*-
"""ML ass3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p1WlD5UJFetPmCs-Lw2MIm455tjjKPEq
"""

import numpy as np
import matplotlib.pyplot as plt

def func(x):
 return (x+3)**2

def gradient(x):
 return 2*(x+3)

X_values = []
Y_values = []

def gradient_descent(starting_point, learning_rate, num_iterations):
    x = starting_point
    for i in range(num_iterations):
        X_values.append(x)
        Y_values.append(func(x))
        grad = gradient(x)
        x = x - learning_rate * grad
        print(f"Iteration {i+1}: x={x}, y={func(x)}")
    return x

starting_point=2
learning_rate=0.1
num_iterations=100

min_x=gradient_descent(starting_point,learning_rate,num_iterations)
print(f"The local minima occurs at x={min_x}")

plt.figure(figsize=(8, 6))

# Plot the function line in blue
x_range = np.linspace(min(X_values), max(X_values), 100)  # Create a range of x values
y_function = func(x_range)  # Calculate corresponding y values
plt.plot(x_range, y_function, 'b-', label='y=(x+3)^2')  # Plot the line

# Plot gradient descent points in red
plt.plot(X_values, Y_values, 'ro', label='Gradient Descent')  # 'ro' for red points

plt.xlabel("X values")
plt.ylabel("Y values")
plt.title("Gradient Descent to Find Local Minima")
plt.grid(True)
plt.legend()
plt.show()